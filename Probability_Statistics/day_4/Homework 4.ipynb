{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Worksheet 8 - Generative models 3\n",
    "\n",
    "Problem 3:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part a)\n",
    "\n",
    "Unpacked and sorted through the directories, have 20 classifications of news types, which are informed by the directory hierarchy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part b)\n",
    "\n",
    "Leverage data-set and hierarchy on scikit-learn. Links to the same directory as specified in the homework. A trainling label will link fo the lableed value according to the directory that it lies in, i.e.: alt.atheism 1, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# Remove strong identifiers of article category\n",
    "newsgroups_train = fetch_20newsgroups(subset='train',remove=('headers', 'footers', 'quotes'))\n",
    "# Remove strong identifiers of article category\n",
    "newsgroups_test = fetch_20newsgroups(subset='test',remove=('headers', 'footers', 'quotes'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(newsgroups_train.filenames.shape)\n",
    "print(newsgroups_test.filenames.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 11,314 documents of training data and 7,532 documents of test data.\n",
    "\n",
    "Part c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "length = newsgroups_train.filenames.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "unique, counts = np.unique(newsgroups_train.target, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "prior_prob = pd.DataFrame({'class':unique, 'prior_prob':counts/length})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fraction of total documents that belong to each class. Appear to be less on the last class.\n",
    "# Appears that the class is transformed from the range 0-19 as opposed to 1-20.\n",
    "prior_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab = {}\n",
    "reverse_vocab = {}\n",
    "count = 0\n",
    "a = open('./vocabulary.txt', 'r')\n",
    "for v in a:\n",
    "    val = v.strip()\n",
    "    vocab[val] = count\n",
    "    reverse_vocab[count] = val\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab['baseball']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize each training document, using the vocabulary document\n",
    "vectorizer = TfidfVectorizer(strip_accents='unicode', decode_error = 'ignore', stop_words='english', vocabulary=vocab)\n",
    "vectors = vectorizer.fit_transform(newsgroups_train.data)\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize the test document, using the vocabulary document\n",
    "vectors_test = vectorizer.fit_transform(newsgroups_test.data)\n",
    "vectors_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part d) Used a different smoothing constant than 1, 1 did not perform as well. MultinomialNB uses logs inherently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "clf = MultinomialNB(alpha=0.046)\n",
    "clf.fit(vectors, newsgroups_train.target)\n",
    "# Naive bayes uses prior probability distributions from above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions:\n",
    "pred = clf.predict(vectors_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The model is', round(metrics.accuracy_score(newsgroups_test.target, pred)*100), '% accurate')\n",
    "print('The model has an error rate of', round((1- metrics.accuracy_score(newsgroups_test.target, pred))*100),'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Worksheet 9 - Clustering\n",
    "\n",
    "Problem 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('./Animals_with_Attributes/Features/README-features.txt', 'r')\n",
    "file_contents = f.read()\n",
    "print (file_contents)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Different animal classes\n",
    "f = open('./Animals_with_Attributes/classes.txt', 'r')\n",
    "classes_str = f.read()\n",
    "print (classes_str)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Different available features\n",
    "f = open('./Animals_with_Attributes/predicates.txt', 'r')\n",
    "features_str = f.read()\n",
    "print (features_str)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classes = ''.join([i for i in classes_str if not i.isdigit()]).split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = ''.join([i for i in features_str if not i.isdigit()]).split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animals_data = pd.read_fwf(\"./Animals_with_Attributes/predicate-matrix-continuous.txt\", header=None).values\n",
    "print('The shape of the data is', animals_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animal_df = pd.DataFrame(data = animals_data, columns = features)\n",
    "animal_df.index = classes\n",
    "animal_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import K Means Package\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Set k = 10\n",
    "km10 = KMeans(n_clusters=10)\n",
    "km10.fit(animals_data)\n",
    "# Get cluster assignment labels\n",
    "labels = km10.labels_\n",
    "# Format results as a DataFrame\n",
    "results = pd.DataFrame([animal_df.index,labels]).T\n",
    "results.columns = ['class', 'cluster']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.groupby('cluster')['class'].apply(list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To me, it looks like the clusters make pretty good sense. The large aquatic/land animals are grouped together, the flying animal is alone, the bears are together, and the household pets are grouped together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 10,10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "HC = linkage(animals_data, 'ward')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Hierarchical Clustering of Animals')\n",
    "plt.xlabel('sample index')\n",
    "plt.ylabel('distance')\n",
    "dendrogram(HC, labels= classes, orientation='right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The hierarchial clusters make sense to me as the larger land animals are grouped together, the smaller land animals are grouped together, and the aquatic animals are grouped together. In these examples, however, I believe the K-means was very comparable, especially when I see the Bat and Monkey family so similar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Worksheet 10 - PCA and SVD\n",
    "\n",
    "Problem 4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pc2 = PCA(2)\n",
    "animals_data2d = pc2.fit_transform(animals_data)\n",
    "print(animals_data2d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Reduced to 2-D dimensionality retained',sum(pc2.explained_variance_ratio_),'of the original datas variance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us plot the hierarchial clusters again:\n",
    "HC2 = linkage(animals_data2d, 'ward')\n",
    "plt.title('Hierarchical Clustering of Animals (PCA 2-D)')\n",
    "plt.xlabel('sample index')\n",
    "plt.ylabel('distance')\n",
    "dendrogram(HC2, labels= classes, orientation='right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot values in 2-D\n",
    "fig = plt.figure(1, figsize=(10, 10))\n",
    "ax = fig.add_subplot(111)\n",
    "for i,point in enumerate(animals_data2d):\n",
    "    ax.annotate(classes[i], xy=point, xytext=point)\n",
    "    \n",
    "plt.scatter(animals_data2d[:,0], animals_data2d[:,1])\n",
    "plt.title('PCA Projection of Animals')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While it does seem sensible, I think a few higher dimensions may yield more accurate results. This just seems to separate aquatic from non-aquatic animals"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
