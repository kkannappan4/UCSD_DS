{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 3\n",
    "\n",
    "\n",
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_dat = pd.read_csv('./wine_original.csv')\n",
    "print(wine_dat.shape)\n",
    "print(wine_dat['class'].value_counts())\n",
    "wine_dat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = wine_dat.copy().drop('class',axis=1)\n",
    "Y = wine_dat['class']\n",
    "\n",
    "# Split into testing and training data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Lasso = L1, Ridge = L2\n",
    "parameters = { 'penalty': ['l1','l2'], \n",
    "              'C':[0.1, 0.5, 1, 2, 3, 4, 5, 10]}\n",
    "logreg = LogisticRegression()\n",
    "clf = GridSearchCV(logreg, parameters, verbose=True, n_jobs=-1)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_pred, y_test)\n",
    "train_acc = accuracy_score(clf.predict(X_train), y_train)\n",
    "print ('Selected Parameters: ', clf.best_params_)\n",
    "print ('\\nTest Accuracy = ' + str(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptron and SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "features = ['alt.atheism', 'comp.graphics', 'sci.space', 'talk.politics.mideast']\n",
    "strip = ('headers', 'footers', 'quotes')\n",
    "\n",
    "train_init = fetch_20newsgroups(subset = 'train', categories=features, remove=strip)\n",
    "test_init = fetch_20newsgroups(subset = 'test', categories=features, remove=strip)\n",
    "\n",
    "X_train = train_init.data\n",
    "y_train = train_init.target\n",
    "X_test = test_init.data\n",
    "y_test = test_init.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(strip_accents='unicode', lowercase=True, decode_error='ignore', \\\n",
    "                             max_features=2000, stop_words='english')\n",
    "X_train_fin = vectorizer.fit_transform(X_train)\n",
    "X_test_fin = vectorizer.transform(X_test)\n",
    "\n",
    "print('Train data:', X_train_fin.shape)\n",
    "print('Test data:', X_test_fin.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "clf = Perceptron(penalty=None)\n",
    "clf.fit(X_train_fin, y_train)\n",
    "y_pred = clf.predict(X_test_fin)\n",
    "print('Test accuracy = ' + str(accuracy_score(y_pred, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "features = [100, 200, 500, 1000, 1500, 2000, 3000]\n",
    "for i in features:\n",
    "    vectorizer = TfidfVectorizer(strip_accents='unicode', lowercase=True, decode_error='ignore', \\\n",
    "                                 max_features=i, stop_words='english')\n",
    "    X_train_fin = vectorizer.fit_transform(X_train)\n",
    "    X_test_fin = vectorizer.transform(X_test)\n",
    "    clf = Perceptron(penalty=None)\n",
    "    clf.fit(X_train_fin, y_train)\n",
    "    y_pred = clf.predict(X_test_fin)\n",
    "    accuracy = accuracy_score(y_pred, y_test)\n",
    "    result.append(accuracy)\n",
    "    print('Test accuracy with top ', i,' features is ', accuracy)\n",
    "    \n",
    "plt.plot(features, result)\n",
    "plt.title('Peceptron: Accuracy Increases with more Features');\n",
    "plt.xlabel('Top (N) Features');\n",
    "plt.ylabel('Accuracy');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indicated by the title plot, we see an overall trend that as we increase the amount of top features fed to the model, the model performs better. Interestingly, however, there seems to be some large jumps with some increases in n, but not in others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "clf = SVC(kernel='linear')\n",
    "clf.fit(X_train_fin, y_train)\n",
    "y_pred = clf.predict(X_test_fin)\n",
    "\n",
    "print('Test accuracy = ' + str(accuracy_score(y_pred, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "features = [100, 200, 500, 1000, 1500, 2000, 3000]\n",
    "for i in features:\n",
    "    vectorizer = TfidfVectorizer(strip_accents='unicode', lowercase=True, decode_error='ignore', \\\n",
    "                                 max_features=i, stop_words='english')\n",
    "    X_train_fin = vectorizer.fit_transform(X_train)\n",
    "    X_test_fin = vectorizer.transform(X_test)\n",
    "    clf = SVC(kernel='linear')\n",
    "    clf.fit(X_train_fin, y_train)\n",
    "    y_pred = clf.predict(X_test_fin)\n",
    "    accuracy = accuracy_score(y_pred, y_test)\n",
    "    result.append(accuracy)\n",
    "    print('Test accuracy with top ', i,' features is ', accuracy)\n",
    "    \n",
    "plt.plot(features, result)\n",
    "plt.title('SVM: Accuracy Increases with more Features');\n",
    "plt.xlabel('Top (N) Features');\n",
    "plt.ylabel('Accuracy');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indicated by the title plot, we see an overall trend that as we increase the amount of top features fed to the model, the model performs better. Different from the perceptron model, SVM seems to steadily improve as we increase n."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 6:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_n, X_valid, y_train_n, y_valid = train_test_split(X_train_fin, y_train, test_size = 0.2, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_acc = 0.0\n",
    "results = []\n",
    "cost = [0.01,0.1,1,10,100]\n",
    "for i in cost:\n",
    "    clf = SVC(kernel='linear', C= i)\n",
    "    clf.fit(X_train_n, y_train_n)\n",
    "    y_pred = clf.predict(X_valid)\n",
    "    accuracy = accuracy_score(y_pred, y_valid)\n",
    "    print('The validation accuracy for C = ', i, 'is ', accuracy)\n",
    "    results.append(accuracy)\n",
    "    if (accuracy > best_acc):\n",
    "        best_cost = i\n",
    "        best_acc = accuracy\n",
    "print('\\nOptimal cost (c): ', best_cost, ', validation accuracy=', best_acc)\n",
    "\n",
    "plt.plot(cost, results);\n",
    "plt.title('SVM: Diminishing Marginal Returns Tuning Cost');\n",
    "plt.xlabel('Cost');\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show();\n",
    "\n",
    "\n",
    "clf = SVC(kernel='linear', C= best_cost)\n",
    "clf.fit(X_train_fin, y_train)\n",
    "y_pred = clf.predict(X_test_fin)\n",
    "accuracy = accuracy_score(y_pred, y_test)\n",
    "print('\\n')\n",
    "print('Test accuracy with optimal c =', best_cost, 'is ', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 7:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_acc = 0.0\n",
    "results = []\n",
    "deg = [1,2,3]\n",
    "\n",
    "for i in deg:\n",
    "    clf = SVC(C=10000, kernel='poly', degree=i)\n",
    "    clf.fit(X_train_n, y_train_n)\n",
    "    y_pred = clf.predict(X_valid)\n",
    "    accuracy = accuracy_score(y_pred, y_valid)\n",
    "    print('Poly validation accuracy with', i, 'degree = ', accuracy)\n",
    "    results.append(accuracy)\n",
    "    if (accuracy > best_acc):\n",
    "        best_deg = i\n",
    "        best_kernel = 'poly'\n",
    "        best_acc = accuracy\n",
    "        \n",
    "for i in ['rbf', 'sigmoid']:\n",
    "    clf = SVC(C=10000, kernel=i)\n",
    "    clf.fit(X_train_n, y_train_n)\n",
    "    y_pred = clf.predict(X_valid)\n",
    "    accuracy = accuracy_score(y_pred, y_valid)\n",
    "    print(i,'validation accuracy =', accuracy)\n",
    "    results.append(accuracy)\n",
    "    if (accuracy > best_acc):\n",
    "        best_kernel = i\n",
    "        best_acc = accuracy\n",
    "\n",
    "if best_kernel != 'poly':\n",
    "    best_degree == np.nan\n",
    "print('\\nBest kernel is ',best_kernel,'best degree is',best_deg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC(C=10000, kernel=best_kernel, degree= best_deg)\n",
    "clf.fit(X_train_fin, y_train)\n",
    "y_pred = clf.predict(X_test_fin)\n",
    "accuracy = accuracy_score(y_pred, y_test)\n",
    "print('Test accuracy using SVM with poly kernel, degree 1 = ', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Kernels\n",
    "\n",
    "Problem 8:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity, laplacian_kernel\n",
    "\n",
    "# Create dictionary to avoid string error\n",
    "kernels = {'cosine_similarity': cosine_similarity, 'laplacian_kernel': laplacian_kernel}\n",
    "for i,j in kernels.items():\n",
    "    clf = SVC(kernel=j)\n",
    "    clf.fit(X_train_fin, y_train)\n",
    "    y_pred = clf.predict(X_test_fin)\n",
    "    accuracy = accuracy_score(y_pred, y_test)\n",
    "    print('Kernel = ', i, ', test accuracy = ', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 9:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in np.arange(0, 1.1, 0.1):\n",
    "    new_train = (a* cosine_similarity(X_train_n)) + ((1-a)* laplacian_kernel(X_train_n))\n",
    "    new_valid = (a* cosine_similarity(X_valid, X_train_n)) + ((1-a)* laplacian_kernel(X_valid, X_train_n))\n",
    "    \n",
    "    clf = SVC(kernel='precomputed')\n",
    "    clf.fit(new_train, y_train_n)\n",
    "    y_pred = clf.predict(new_valid)\n",
    "    accuracy = accuracy_score(y_pred, y_valid)\n",
    "    print('Validation accuracy with alpha = ', a, 'is ', accuracy)\n",
    "    if (accuracy > best_acc):\n",
    "        best_alpha = a\n",
    "        best_acc = accuracy\n",
    "        \n",
    "new_train = (best_alpha* cosine_similarity(X_train_fin)) + ((1-best_alpha)* laplacian_kernel(X_train_fin))\n",
    "new_valid = (best_alpha* cosine_similarity(X_test_fin, X_train_fin)) + ((1-best_alpha)* laplacian_kernel(X_test_fin, X_train_fin))\n",
    "clf = SVC(kernel='precomputed')\n",
    "clf.fit(new_train, y_train)\n",
    "y_pred = clf.predict(new_valid)\n",
    "accuracy = accuracy_score(y_pred, y_test)\n",
    "print('\\n')\n",
    "print('Test accuracy with alpha:', best_alpha, '= ', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A valid kernel must satisfy Mercer's condition: the resulting Kernel Matrix is symmetric positive semi-definite and the positive eigenvalues follows from that. In this case, we know that the kernel has been specified to be a >= 0, which implies the integral will be positive. Since we have two valid Kernels and we know that they can be expressed as the inner product of some feature space, we know that the new kernel is valid as well."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
