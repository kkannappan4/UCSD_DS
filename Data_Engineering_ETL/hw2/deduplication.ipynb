{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import argparse\n",
    "import csv\n",
    "import os\n",
    "\n",
    "import dedupe\n",
    "import psycopg2\n",
    "from psycopg2.extras import DictCursor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "KEY_FIELD = 'visitor_id'\n",
    "SOURCE_TABLE = 'visitors'\n",
    "\n",
    "FIELDS =  [{'field': 'firstname', 'variable name': 'firstname',\n",
    "           'type': 'String','has missing': True},\n",
    "           {'field': 'lastname', 'variable name': 'lastname',\n",
    "           'type': 'String','has missing': True},\n",
    "           {'field': 'uin', 'variable name': 'uin',\n",
    "           'type': 'String','has missing': True},\n",
    "           {'field': 'meeting_loc', 'variable name': 'meeting_loc',\n",
    "           'type': 'String','has missing': True}\n",
    "           ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def candidates_gen(result_set):\n",
    "    lset = set\n",
    "    block_id = None\n",
    "    records = []\n",
    "    i = 0\n",
    "    for row in result_set:\n",
    "        if row['block_id'] != block_id:\n",
    "            if records:\n",
    "                yield records\n",
    "            \n",
    "            block_id = row['block_id']\n",
    "            records = []\n",
    "            i += 1\n",
    "            \n",
    "            if i % 10000 == 0:\n",
    "                print ('{} blocks'.format(i))\n",
    "\n",
    "        smaller_ids = row['smaller_ids']\n",
    "        if smaller_ids:\n",
    "            smaller_ids = lset(smaller_ids.split(','))\n",
    "        else:\n",
    "            smaller_ids = lset([])\n",
    "        \n",
    "        records.append((row[KEY_FIELD], row, smaller_ids))\n",
    "    \n",
    "    if records:\n",
    "        yield records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "deduper = dedupe.Dedupe(FIELDS)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "deduper.classifier = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    con = psycopg2.connect(database='postgres',\n",
    "                          host='lva1-gendevdb01',\n",
    "                           password='epWU32peDN',\n",
    "                          cursor_factory=DictCursor)\n",
    "    print (\"I've connected\")\n",
    "except Exception as e:\n",
    "    print (e)\n",
    "c = con.cursor()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing null values to preserve script, minimal data loss - still robust clusters can be made\n",
    "c.execute('SELECT COUNT(*) AS count FROM %s where firstname is not null and firstname <> \\'\\' and lastname is not null and lastname <> \\'\\' and uin is not null and uin <> \\'\\' ' % SOURCE_TABLE)\n",
    "row = c.fetchone()\n",
    "count = row['count']\n",
    "sample_size = int(count * 0.05)\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modifying for complete records\n",
    "print ('Generating sample of {} records'.format(sample_size))\n",
    "with con.cursor('deduper') as c_deduper:\n",
    "    c_deduper.execute('SELECT visitor_id,lastname,firstname,uin,meeting_loc FROM %s where firstname is not null and firstname <> \\'\\' and lastname is not null and lastname <> \\'\\' and uin is not null and uin <> \\'\\' ' % SOURCE_TABLE)\n",
    "    temp_d = dict((i, row) for i, row in enumerate(c_deduper))\n",
    "    deduper.sample(temp_d, sample_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Starting active learning')\n",
    "dedupe.convenience.consoleLabel(deduper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('preparing training')\n",
    "deduper.prepare_training(temp_d, sample_size =sample_size)\n",
    "print ('Starting training')\n",
    "deduper.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Saving new training file to {}'.format('train.json'))\n",
    "with open('train.json', 'w') as training_file:\n",
    "    deduper.writeTraining(training_file)\n",
    "\n",
    "deduper.cleanupTraining()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Creating blocking_map table')\n",
    "c.execute(\"\"\"\n",
    "    DROP TABLE IF EXISTS blocking_map\n",
    "    \"\"\")\n",
    "c.execute(\"\"\"\n",
    "    CREATE TABLE blocking_map\n",
    "    (block_key VARCHAR(200), %s INTEGER)\n",
    "    \"\"\" % KEY_FIELD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for field in deduper.blocker.index_fields:\n",
    "    print ('Selecting distinct values for \"{}\"'.format(field))\n",
    "    c_index = con.cursor('index')\n",
    "    c_index.execute(\"\"\"\n",
    "        SELECT DISTINCT %s FROM %s\n",
    "        \"\"\" % (field, SOURCE_TABLE))\n",
    "    field_data = (row[field] for row in c_index)\n",
    "    deduper.blocker.index(field_data, field)\n",
    "    c_index.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Generating blocking map')\n",
    "c_block = con.cursor('block')\n",
    "c_block.execute(\"\"\"\n",
    "    SELECT * FROM %s\n",
    "    \"\"\" % SOURCE_TABLE)\n",
    "full_data = ((row[KEY_FIELD], row) for row in c_block)\n",
    "b_data = deduper.blocker(full_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Inserting blocks into blocking_map')\n",
    "csv_file = tempfile.NamedTemporaryFile(prefix='blocks_', delete=False, mode ='w')\n",
    "csv_writer = csv.writer(csv_file)\n",
    "for x in b_data:\n",
    "    csv_writer.writerow(list(x))\n",
    "#csv_writer.writerows(b_data)\n",
    "csv_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open(csv_file.name, 'r')\n",
    "c.copy_expert(\"COPY blocking_map FROM STDIN CSV\", f)\n",
    "f.close()\n",
    "\n",
    "os.remove(csv_file.name)\n",
    "\n",
    "con.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Indexing blocks')\n",
    "c.execute(\"\"\"\n",
    "    CREATE INDEX blocking_map_key_idx ON blocking_map (block_key)\n",
    "    \"\"\")\n",
    "c.execute(\"DROP TABLE IF EXISTS plural_key\")\n",
    "c.execute(\"DROP TABLE IF EXISTS plural_block\")\n",
    "c.execute(\"DROP TABLE IF EXISTS covered_blocks\")\n",
    "c.execute(\"DROP TABLE IF EXISTS smaller_coverage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Calculating plural_key')\n",
    "c.execute(\"\"\"\n",
    "    CREATE TABLE plural_key\n",
    "    (block_key VARCHAR(200),\n",
    "    block_id SERIAL PRIMARY KEY)\n",
    "    \"\"\")\n",
    "c.execute(\"\"\"\n",
    "    INSERT INTO plural_key (block_key)\n",
    "    SELECT block_key FROM blocking_map\n",
    "    GROUP BY block_key HAVING COUNT(*) > 1\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Indexing block_key')\n",
    "c.execute(\"\"\"\n",
    "    CREATE UNIQUE INDEX block_key_idx ON plural_key (block_key)\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Calculating plural_block')\n",
    "c.execute(\"\"\"\n",
    "    CREATE TABLE plural_block\n",
    "    AS (SELECT block_id, %s\n",
    "    FROM blocking_map INNER JOIN plural_key\n",
    "    USING (block_key))\n",
    "    \"\"\" % KEY_FIELD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Adding {} index'.format(KEY_FIELD))\n",
    "c.execute(\"\"\"\n",
    "    CREATE INDEX plural_block_%s_idx\n",
    "    ON plural_block (%s)\n",
    "    \"\"\" % (KEY_FIELD, KEY_FIELD))\n",
    "c.execute(\"\"\"\n",
    "    CREATE UNIQUE INDEX plural_block_block_id_%s_uniq\n",
    "    ON plural_block (block_id, %s)\n",
    "    \"\"\" % (KEY_FIELD, KEY_FIELD))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Creating covered_blocks')\n",
    "c.execute(\"\"\"\n",
    "    CREATE TABLE covered_blocks AS\n",
    "    (SELECT %s,\n",
    "    string_agg(CAST(block_id AS TEXT), ','\n",
    "    ORDER BY block_id) AS sorted_ids\n",
    "    FROM plural_block\n",
    "    GROUP BY %s)\n",
    "    \"\"\" % (KEY_FIELD, KEY_FIELD))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Indexing covered_blocks')\n",
    "c.execute(\"\"\"\n",
    "    CREATE UNIQUE INDEX covered_blocks_%s_idx\n",
    "    ON covered_blocks (%s)\n",
    "    \"\"\" % (KEY_FIELD, KEY_FIELD))\n",
    "print ('Committing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print ('Creating smaller_coverage')\n",
    "c.execute(\"\"\"\n",
    "    CREATE TABLE smaller_coverage AS\n",
    "    (SELECT %s, block_id,\n",
    "    TRIM(',' FROM split_part(sorted_ids,\n",
    "    CAST(block_id AS TEXT), 1))\n",
    "    AS smaller_ids\n",
    "    FROM plural_block\n",
    "    INNER JOIN covered_blocks\n",
    "    USING (%s))\n",
    "    \"\"\" % (KEY_FIELD, KEY_FIELD))\n",
    "con.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print ('Clustering...')\n",
    "c_cluster = con.cursor('cluster')\n",
    "c_cluster.execute(\"\"\"\n",
    "    SELECT *\n",
    "    FROM smaller_coverage\n",
    "    INNER JOIN %s\n",
    "    USING (%s)\n",
    "    ORDER BY (block_id)\n",
    "    LIMIT 100\n",
    "    \"\"\" % (SOURCE_TABLE, KEY_FIELD))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clustered_dupes = deduper.matchBlocks(candidates_gen(c_cluster), threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print ('Creating entity_map table')\n",
    "c.execute(\"DROP TABLE IF EXISTS entity_map\")\n",
    "c.execute(\"\"\"\n",
    "      CREATE TABLE entity_map (\n",
    "      %s INTEGER,\n",
    "      canon_id INTEGER,\n",
    "      cluster_score FLOAT,\n",
    "      PRIMARY KEY(%s)\n",
    "      )\"\"\" % (KEY_FIELD, KEY_FIELD))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print ('Inserting entities into entity_map')\n",
    "for cluster, scores in clustered_dupes:\n",
    "    cluster_id = cluster[0]\n",
    "    for key_field, score in zip(cluster, scores):\n",
    "        c.execute(\"\"\"\n",
    "              INSERT INTO entity_map\n",
    "              (%s, canon_id, cluster_score)\n",
    "              VALUES (%s, %s, %s)\n",
    "              \"\"\" % (KEY_FIELD, key_field, cluster_id, score))\n",
    "        con.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
